# -*- coding: utf-8 -*-
"""Prakhar ML Project Fake news finall

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fVPcl0wqB_l6kZP2PVd6GRQnutp0vbvT

The dataset contains the following:

-Unique ID for each news piece

-Title for each news piece

-Author of each news piece

-Text of each news piece

-A label or "tag" that is marked "1" for fake news and "0" for real news\
"""

import numpy as np
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

import nltk
nltk.download('stopwords')

"""These are the words we are going to remove from the dataset\:

"""

print(stopwords.words('english'))

"""Pre-procesing the data"""

organiseddataset= pd.read_csv('train.csv', encoding='latin-1', on_bad_lines='skip')

organiseddataset.shape

organiseddataset.head()

#seeing the values that are missing
organiseddataset.isnull().sum()

#replacing missing values with empty string
organiseddataset=organiseddataset.fillna('')

#combining the author name and the news title into a single entity
organiseddataset['combined']=organiseddataset['author'] + organiseddataset['title']

print(organiseddataset['combined'])

#separating the "label" or flag from the rest of the data
A=organiseddataset.drop(columns='label',axis=1)
B=organiseddataset['label']

print(A)
print(B)

"""Next step: Stemming: Reducing a word to its root word to improve performance"""

port_stem = PorterStemmer()

def stem(content):
    stemmed_content = re.sub('[^a-zA-Z]',' ',content)
    stemmed_content = stemmed_content.lower()
    stemmed_content = stemmed_content.split()
    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
    stemmed_content = ' '.join(stemmed_content)
    return stemmed_content

organiseddataset['combined']=organiseddataset['combined'].apply(stem)

print(organiseddataset['combined'])

#separating the changed data and label once again
A=organiseddataset['combined'].values
B=organiseddataset['label'].values

print(A)

print(B)

vector = TfidfVectorizer()
vector.fit(A)

A= vector.transform(A)

print(A)

"""Now we split the dataset into, training data, and test data

"""

A_train, A_test, B_train, B_test= train_test_split(A,B, test_size=0.2, stratify=B, random_state=2)

model=LogisticRegression()

model.fit(A_train, B_train)

"""Checking the accuracy score"""

# accuracy score on the training data
A_train_prediction = model.predict(A_train)
training_data_accuracy = accuracy_score(A_train_prediction, B_train)

print('Accuracy score of the training data : ', training_data_accuracy)

# accuracy score on the test data
A_test_prediction = model.predict(A_test)
test_data_accuracy = accuracy_score(A_test_prediction, B_test)

print('Accuracy score of the test data : ', test_data_accuracy)

"""Random Prediction Checker

"""

A_new = A_test[5]

prediction = model.predict(A_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is Fake')

print(B_test[5])